{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import timedelta\n",
    "from math import sqrt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.ar_model import ar_select_order\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Business Goal\n",
    "\n",
    "Build a model that can predict tomorrows temperature, given the temprature until today, as precisely as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Get the Data\n",
    "\n",
    "### 2.1) Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temp_data():\n",
    "    \"\"\"\n",
    "    read temperature data\n",
    "    \"\"\"\n",
    "    return pd.read_csv(\n",
    "        './data/TG_STAID002759.txt', \n",
    "        parse_dates=True, \n",
    "        sep=',', \n",
    "        skiprows=19, \n",
    "        index_col=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_data(year=1950):\n",
    "    df = get_temp_data()\n",
    "\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "    df.index.freq = \"D\" # TODO: try W\n",
    "\n",
    "    df.rename(columns={'TG':'temp'}, inplace=True)\n",
    "    df.index.names = ['date']\n",
    "\n",
    "    return df[df.index.year > year][['temp']].copy()\n",
    "\n",
    "df = get_clean_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 3) Train-Test-Split \n",
    "# TODO: remove and update future numeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df[:-365].copy()\n",
    "# df_test = df[-365:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4) Visualize the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.1) Actual temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(df, y=\"temp\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend(df):\n",
    "    \"\"\" build and return trend \"\"\"\n",
    "    timestep = pd.DataFrame(range(len(df)))\n",
    "    \n",
    "    X = pd.DataFrame(range(len(df)))\n",
    "    y = df['temp']\n",
    "    \n",
    "    m = LinearRegression()\n",
    "    m.fit(X, y)\n",
    "\n",
    "    return m.predict(X)\n",
    "\n",
    "trend = get_trend(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=df.index.values, y=df['temp'], name='Temperature'))\n",
    "fig.add_trace(go.Scatter(x=df.index.values, y=trend, name='Trend'))\n",
    "\n",
    "fig.show() # Looks like global warming is not an anti-globalization fantasy ðŸ˜• "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3) Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df.index.month)['temp'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seasonality_ohe(df):\n",
    "    return pd.get_dummies(df.index.month, drop_first=True, prefix='month').set_index(df.index)\n",
    "\n",
    "def get_seasonal_trend(df):\n",
    "    X = get_seasonality_ohe(df)\n",
    "    X['timestep'] = range(len(df))\n",
    "    \n",
    "    y = df['temp']\n",
    "    m = LinearRegression()\n",
    "    m.fit(X, y)\n",
    "\n",
    "    return m.predict(X) # it includes overall trend\n",
    "\n",
    "seasonal_trend = get_seasonal_trend(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=df.index.values, y=df['temp'], name='Temperature'))\n",
    "fig.add_trace(go.Scatter(x=df.index.values, y=seasonal_trend, name='Seasonal trend'))\n",
    "fig.add_trace(go.Scatter(x=df.index, y=trend, name='Trend'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4) Remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder = df['temp'].values - seasonal_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df, x = df.index, y=remainder, trendline=\"ols\")\n",
    "fig.update_traces(showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5) Autoregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lags(df, n=3):\n",
    "    for i in range(1,n+1):\n",
    "        df[f\"lag{i}\"] = df['remainder'].shift(i)\n",
    "        \n",
    "    df.dropna()\n",
    "        \n",
    "    return df\n",
    "\n",
    "tmp = add_lags(pd.DataFrame(remainder, columns=['remainder']))\n",
    "\n",
    "corr = tmp.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = tmp.melt(id_vars=['remainder'])\n",
    "\n",
    "traces = px.scatter(melted, x=\"value\", y=\"remainder\", color='variable', trendline=\"ols\")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(traces.data[1])\n",
    "fig.add_trace(traces.data[3])\n",
    "fig.add_trace(traces.data[5])\n",
    "fig.update_traces(showlegend=True)\n",
    "fig.show()\n",
    "\n",
    "# Note: this plot shows us correlation between previous value (lagN) and current remainder-value. \n",
    "# The strongest correlation is for lag1. Meaning that yesterday's weather has the biggest impact to today's weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correnation between remainder and lags (X is a lag level, y is correlation)\n",
    "# lag0 is correlates to remainder with corr=1 (because there is no lag and lag0=remainder)\n",
    "\n",
    "print(plot_acf(remainder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial (direct) correlation between lag level and remainder (that is not explained by previous lag with lower level)\n",
    "print(plot_pacf(remainder, method='ywm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ar_lags(remainder):\n",
    "    \"\"\" number of lags (previous days) that should be used by autoregression model \"\"\"\n",
    "    selected_order = ar_select_order(remainder, maxlag=10)\n",
    "\n",
    "    return selected_order.ar_lags\n",
    "\n",
    "get_ar_lags(remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remainder_ar(remainder):\n",
    "    \"\"\" calculate remainder parts that could be deduced from previous days \"\"\"\n",
    "    \n",
    "    model_ar = AutoReg(endog=remainder, lags=len(get_ar_lags(remainder))).fit() # TODO: check if number of legs can be taken from selected_order directly\n",
    "\n",
    "    return model_ar.predict()\n",
    "\n",
    "remainder_ar = get_remainder_ar(remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame({\n",
    "    'temp': df['temp'],\n",
    "    'explained_by_ar_and_seasonality': remainder_ar + seasonal_trend,\n",
    "    'date': df.index\n",
    "})\n",
    "\n",
    "tmp = tmp.dropna().melt(id_vars=['date'])\n",
    "\n",
    "line = px.line(tmp[pd.to_datetime(tmp['date']).dt.year > 2020], x=\"date\", y=\"value\", color='variable')\n",
    "line.show() # feel free to zoom plot in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame({\n",
    "    'remainder': remainder,\n",
    "    'remainder_ar': remainder_ar,\n",
    "    'noise': remainder - remainder_ar,\n",
    "    'date': df.index\n",
    "})\n",
    "\n",
    "tmp = tmp.dropna().melt(id_vars=['date'])\n",
    "\n",
    "line = px.line(tmp[pd.to_datetime(tmp['date']).dt.year > 2020], x=\"date\", y=\"value\", color='variable')\n",
    "\n",
    "line.show() # feel free to zoom plot in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standart deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame({\n",
    "    'temp': df['temp'],\n",
    "    'seasonal_trend': seasonal_trend,\n",
    "    'remainder': remainder,\n",
    "    'noise': remainder - remainder_ar\n",
    "})\n",
    "tmp = tmp.dropna()\n",
    "tmp.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: does it work if you remove return statements?\n",
    "\n",
    "# def add_trend(df):\n",
    "#     df['trend'] = get_trend(df)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "def add_timestep(df):\n",
    "    \n",
    "#     print('add_timestep', df.shape)\n",
    "    \n",
    "    df['timestep'] = range(len(df))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# def add_seasonality_ohe(df):\n",
    "#     print('add_seasonality_ohe', df.shape)\n",
    "#     return df.join(get_seasonality_ohe(df))\n",
    "\n",
    "def add_seasonal_trend_and_ohe(df):\n",
    "\n",
    "#     print('add_seasonal_trend_and_ohe', df.shape)\n",
    "\n",
    "    df['seasonal_trend'] = get_seasonal_trend(df)\n",
    "\n",
    "    return add_seasonality_ohe(df)\n",
    "\n",
    "def add_seasonality_ohe(df):\n",
    "    return df.join(get_seasonality_ohe(df))\n",
    "\n",
    "def add_remainder(df):\n",
    "    \n",
    "#     print('add_remainder', df.shape)\n",
    "#     print(df)\n",
    "    \n",
    "    df['remainder'] = df['temp'] - df['seasonal_trend'] #TODO: does it work without .values ?\n",
    "    \n",
    "    return df\n",
    "\n",
    "# def add_lags(df):\n",
    "#     df['lag1'] = df['remainder'].shift(1)\n",
    "#     df['lag2'] = df['remainder'].shift(2)\n",
    "#     df['lag3'] = df['remainder'].shift(3)\n",
    "\n",
    "#     df.dropna()\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# def add_remainder_ar(df):\n",
    "#     df['remainder_ar'] = get_remainder_ar(df['remainder'])\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "class Databag:\n",
    "    def drop_remainder_and_seasonal_trend(df):\n",
    "        \"\"\" \n",
    "        this method removes features and keeps them for the future use.\n",
    "        namely feature \"remainder\" is important - we drop it because we \n",
    "        don't need to use it for fitting model. But later we will need \n",
    "        it for building lag1 for constructing the next day features.\n",
    "        \n",
    "        seasonal_trend and remainder cannot be calculated for forecasting \n",
    "        because they are calculated based on the \"temp\" value for the future \n",
    "        that we don't know (we are trying to predict it).\n",
    "        \"\"\"\n",
    "        \n",
    "        Databag.remainder = df['remainder']\n",
    "\n",
    "        return df.drop(columns=['seasonal_trend', 'remainder'])\n",
    "\n",
    "def dropna(df):\n",
    "    \n",
    "#     print('dropna', df.shape)\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "# dropna(add_remainder(add_seasonal_trend_and_ohe(add_timestep(df))))\n",
    "\n",
    "# # this pipeline can be used for train and test data (it does not use \"temp\" column)\n",
    "# pipeline_without_temp = make_pipeline(\n",
    "#     FunctionTransformer(add_timestep),\n",
    "#     FunctionTransformer(add_seasonal_trend_and_ohe),\n",
    "# #     FunctionTransformer(add_remainder_ar),\n",
    "#     FunctionTransformer(dropna), # TODO: can it be done more python'ish?\n",
    "# )\n",
    "\n",
    "def drop_remainder_and_seasonal_trend(df):\n",
    "    # seasonal_trend and remainder cannot be calculated for forecasting because they are calculated \n",
    "    # based on the \"temp\" value for the future that we don't know (we are trying to predict it)\n",
    "    return df.drop(columns=['seasonal_trend', 'remainder'])\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    FunctionTransformer(add_timestep),\n",
    "    FunctionTransformer(add_seasonal_trend_and_ohe),\n",
    "    FunctionTransformer(add_remainder),\n",
    "    FunctionTransformer(add_lags),\n",
    "    FunctionTransformer(dropna), # TODO: can it be done more python'ish?\n",
    "#     FunctionTransformer(drop_seasonal_trend), # TODO: can it be done more python'ish?\n",
    "    FunctionTransformer(Databag.drop_remainder_and_seasonal_trend), # TODO: can it be done more python'ish?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_clean_data()\n",
    "\n",
    "df_train = df[:-365].copy()\n",
    "df_test = df[-365:].copy()\n",
    "\n",
    "df_train_fe = pipeline.transform(df_train)\n",
    "\n",
    "X_train = df_train_fe.drop(columns=['temp']).copy()\n",
    "y_train = df_train_fe['temp'].copy()\n",
    "\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LinearRegression()\n",
    "m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1) Run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = X_train\n",
    "# history['temp'] = y_train\n",
    "# history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering for predicting tomorrow's weather\n",
    "def build_future_features_from_past(past, remainder):\n",
    "    date = past.index[0] + timedelta(1)\n",
    "\n",
    "    future = pd.DataFrame(index=[date])\n",
    "    future['timestep'] = past['timestep'][0] + 1\n",
    "\n",
    "    ohe = pd.get_dummies(range(1,13), drop_first=True, prefix='month')[date.month-1:date.month]\n",
    "    for m in ohe.columns:\n",
    "        future[m] = ohe.iloc[0][m]\n",
    "\n",
    "    future['lag1'] = remainder\n",
    "    future['lag2'] = past['lag1'][0]\n",
    "    future['lag3'] = past['lag2'][0]\n",
    "    \n",
    "    return future\n",
    "\n",
    "future_features = build_future_features_from_past(X_train.tail(1), Databag.remainder.tail(1)[0])\n",
    "future_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.predict(future_features), df_test.loc[future_features.index[0]]['temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Cross-Validate and Optimize Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1) Evaluate the model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_split = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "time_series_split = ts_split.split(X_train, y_train)\n",
    "\n",
    "# these are the 'test scores' in the **training** data.\n",
    "result = cross_val_score(estimator=m,\n",
    "                         X=X_train, y=y_train,\n",
    "                         cv=time_series_split)\n",
    "result.mean(), result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2) Evaluate the model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_clean_data()\n",
    "\n",
    "# df[-5:-4]\n",
    "\n",
    "# # for i in range(365, 1, -1):\n",
    "# #     print(i)\n",
    "\n",
    "# # for t in df.index:\n",
    "# #     print(t)\n",
    "\n",
    "# # df.append(pd.DataFrame({'temp': 123}, index=[pd.to_datetime('2023-10-01')]))\n",
    "\n",
    "# # df_fe = pipeline.transform(df)\n",
    "# # df_fe.filter(items=[pd.to_datetime('2020-10-01')], axis=0)\n",
    "# # type(Databag.remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the list history and performing rolling forecast\n",
    "\n",
    "# history = [x for x in train]\n",
    "\n",
    "df = get_clean_data()\n",
    "\n",
    "predictions = list()\n",
    "actuals = list()\n",
    "dates = list()\n",
    "\n",
    "m = LinearRegression()\n",
    "\n",
    "# walk-forward validation\n",
    "for i in range(365, 1, -1):\n",
    "    \n",
    "    df_train = df[:-i].copy()\n",
    "    df_test = df[-i:-i+1].copy()\n",
    "    \n",
    "    df_train_fe = pipeline.transform(df_train)\n",
    "    last_reminder = Databag.remainder.tail(1)[0] # <-- Databag.remainder is set during transform-method call\n",
    "\n",
    "    last_day = df_train_fe.tail(1)\n",
    "    future_features = build_future_features_from_past(last_day, last_reminder)\n",
    "\n",
    "    X_train = df_train_fe.drop(columns=['temp']).copy()\n",
    "    y_train = df_train_fe['temp'].copy()\n",
    "\n",
    "    m.fit(X_train, y_train)\n",
    "    y_pred = m.predict(future_features)[0]\n",
    "\n",
    "    y_test = df_test['temp'][0]\n",
    "#     df_train.append(y_test)\n",
    "\n",
    "    df_train.append(df_test)\n",
    "\n",
    "    predictions.append(y_pred)\n",
    "    actuals.append(int(y_test))\n",
    "    dates.append(future_features.index[0])\n",
    "    \n",
    "#     print('%s, predicted=%f, expected=%f' % (future_features.index[0], y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame({\n",
    "    'predicted': predictions,\n",
    "    'actual': actuals,\n",
    "    'dates': dates\n",
    "})\n",
    "\n",
    "tmp = tmp.dropna().melt(id_vars=['dates'])\n",
    "\n",
    "fig = px.line(tmp, x=\"dates\", y=\"value\", color='variable')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate forecasts\n",
    "rmse = sqrt(mean_squared_error(actuals, predictions))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns=['temp']).copy()\n",
    "y_test = df_train_fe['temp'].copy()\n",
    "\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_fe = feature_engineer(df_test)\n",
    "\n",
    "y_test = df_test_fe.copy().iloc[:,0]\n",
    "X_test = df_test_fe.copy().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = round(m.score(X_test, y_test), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The R-squared of our model is {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (random-forest-fennel-student-code)",
   "language": "python",
   "name": "pycharm-1d600196"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
