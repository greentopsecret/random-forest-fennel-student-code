{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB movie reviews dataset: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "* 25000 positive & 25000 negative reviews\n",
    "* 50/50 training/test split\n",
    "* 7 stars or more -> positive review\n",
    "* 4 starts or fewer -> negative review\n",
    "* at most 30 reviews per movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(dataset):\n",
    "    corpus = []\n",
    "    labels = []\n",
    "    base_path = '/Users/maxim/codebase/python/spiced_projects/data/aclImdb/'\n",
    "    for rev in ['pos', 'neg']:\n",
    "        for file in os.listdir(base_path + dataset + '/'+ rev + '/'):\n",
    "            file_path = base_path + dataset + '/'+ rev + '/' + file\n",
    "            with open(file_path, 'r') as f:\n",
    "                corpus.append(f.read())\n",
    "                if rev == 'pos':\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "    return corpus, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train, y_train = read_corpus('train')\n",
    "corpus_test, y_test = read_corpus('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approaches\n",
    "\n",
    "1. rule-based (unsupervised)\n",
    "2. machine learning (supervised & unsupervised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.a. *Simple rule-based approach*: lexicon-based method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with two lexicons of words associated with positive and negative sentiments.\n",
    "\n",
    "`positive-words.txt`: https://gist.github.com/mkulakowski2/4289437\n",
    "\n",
    "`negative-words.txt`: https://gist.github.com/mkulakowski2/4289441"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's imagine you have an unlabeled dataset of movie reviews. How would you use these lists of positive and negative words to infer the sentiment of the reviews?\n",
    "* count positive and negative words from the lexicon in each review and assign majority class\n",
    "* same as above, but remove all occurrences of \"not + [word]\" (or count them in the opposite category)\n",
    "* determine sentiment by sentences, count positive vs negative sentences in a review\n",
    "* apply weighting schemes to words (e.g. bad=1, garbage=2; superlatives)\n",
    "* first/last word in review that is in either of the lexicons determines the sentiment (e.g. \"I thought it was a _fantastic_...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words(sentiment):\n",
    "    f = open(f'/Users/maxim/codebase/python/spiced_projects/data/posneg/{sentiment}-words.txt', mode='r')\n",
    "    result = f.readlines()\n",
    "    f.close()\n",
    "    result = [line.strip('\\n') for line in result if not line.startswith(';') and len(line)>1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_sentiment(corpus, neg_lexicon, pos_lexicon):\n",
    "    y_pred = []\n",
    "    for text in corpus:\n",
    "        n_pos = len([w for w in pos_lexicon if w in text])\n",
    "        n_neg = len([w for w in neg_lexicon if w in text])\n",
    "        if n_pos > n_neg:\n",
    "            y_pred.append(1)\n",
    "        elif n_pos < n_neg:\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(np.random.choice([0, 1]))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = read_words('positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = read_words('negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lexicon = determine_sentiment(corpus_test, negative_words, positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66536"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_lexicon, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b. *Advanced rule-based approach*: VADER Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[VADER](https://github.com/cjhutto/vaderSentiment) (Valence Aware Dictionary and sEntiment Reasoner) is a rule-based model for sentiment analysis that takes into account polarity (positive vs. negative) but also intensity of a sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your tasks**\n",
    "\n",
    "1. Take a look at the Vader github repo and try to answer these questions: https://github.com/cjhutto/vaderSentiment\n",
    "\n",
    "    * Locate the \"lexicon\" (dictionary). What can we find in the dictionary, and more specifically: what are the values in the file representing (check out the README)?\n",
    "    * Locate the implementation of the \"rules\":\n",
    "        * Does vader take punctuation into account?\n",
    "        * Which words intensify a sentiment?\n",
    "        * What happens if one word is in ALL CAPS? What if the whole text is in ALL CAPS?\n",
    "\n",
    "\n",
    "2. Implement sentiment analysis using VADER, following the README file here: https://github.com/cjhutto/vaderSentiment#code-examples\n",
    "\n",
    "    * For each review in your test corpus, determine the sentiment (positive or negative), and compare that with the labels for your test set to determine accuracy\n",
    "    * How does this compare with the accuracy of the simple lexicon-based approach?\n",
    "\n",
    "\n",
    "3. For your project:\n",
    "\n",
    "    * Get tweets from MongoDB\n",
    "    * Clean the tweets\n",
    "    * Do sentiment analysis with VADER\n",
    "    * Save tweet and sentiment in postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_sentiment_using_vader(sentences):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    y_pred = []\n",
    "    for sentence in sentences:\n",
    "        vs = analyzer.polarity_scores(sentence)\n",
    "        y_pred.append(1 if vs['compound'] > 0 else 0)\n",
    "#         print(\"{:-<5} {}\".format(sentence, str(vs)))\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "# sentences = [\n",
    "#     'This movie was good',\n",
    "#     'This movie was GOOD',\n",
    "#     'This movie WAS good',\n",
    "#     'This MOVIE was good',\n",
    "#     'THIS MOVIE WAS GOOD',\n",
    "#     'This movie was goooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooood',\n",
    "# ]\n",
    "# determine_sentiment_using_vader(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lexicon_vader = determine_sentiment_using_vader(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6974"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_lexicon_vader, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdasd//ff'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '///asdasd//ff/'\n",
    "s.strip('//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
